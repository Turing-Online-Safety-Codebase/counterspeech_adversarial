{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/counterspeech/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tqdm\n",
    "import datetime as dt\n",
    "from io import StringIO\n",
    "\n",
    "import azure.cosmos.cosmos_client as azurecosmos\n",
    "import azure.storage.blob as azureblob\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "from cs_config import *\n",
    "from cs_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmos Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cosmos = get_cosmos_client(Cosmos.host, Cosmos.key, Cosmos.footballer_db, Cosmos.footballer_container)\n",
    "m_cosmos = get_cosmos_client(Cosmos.host, Cosmos.key, Cosmos.mps_db, Cosmos.mps_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "\n",
    "Query results (ie. tweets) are returned as lists of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select: whole documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying central: SELECT * FROM c OFFSET 0 LIMIT 1\n",
      "1 results returned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['created_at', 'id', 'id_str', 'text', 'source', 'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'quote_count', 'reply_count', 'retweet_count', 'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms', 'id_num', 'date', 'datetime', '_rid', '_self', '_etag', '_attachments', 'user_id', 'text_replaced', 'seed_MP', 'non_seed_USER', 'MP', 'text_replaced_b', 'no_content', 'valid_lang', 'seed_author', 'type_RT', 'type_QT', 'type_RP', 'type_SA', 'type_str', 'seed_parent', 'bucket', 'valid', 'processed', '_ts'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xcd{,,\\xb6iRZ.\\xc0\\xc2\\xe1\\x94\\x17\\x1c)\\xecW \\xc9\\xf6\\xf6\\xe3\\x8a\\xc7\\x80@\\x80\\xec\\xdc\\xc1\\xd1\\x04S\\xe1\\xf59<mM\\xdd\\xe4\\x08\\xeb\\x88),\\xcbl\\xa3\\x0e\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08']\n",
      "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
      "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'']\n",
      "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 T\\xad\\xd5\\xc2\\xed\\x9b\\xa8\\xb5\\xa7\\x11\\x83\\xaa\\xa6\\xb7\\xdb\\x95\\xd3f\\xfa\\x1d\\xe9\\xe0']\n",
      "Bad pipe message: %s [b'\\xf4\\xb1', b\"\\xe4\\x7f\\x9a\\x00\\x8f\\xec\\xd1\\xde\\xe0\\xc7i\\x80\\xe3s\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00\"]\n",
      "Bad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x03\\x03\\x02\\x03\\x03\\x01\\x02\\x01\\x03\\x02\\x02\\x02\\x04\\x02\\x05\\x02\\x06\\x02']\n",
      "Bad pipe message: %s [b'\\xfcM.\\xd8\\xa0\\xf8\\xe8\\xaf\\x00\\xcb\\xc9\\x92\\xf9\\xe2\\xbf\\xe2\\x17\\xaa\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00', b'']\n",
      "Bad pipe message: %s [b'\\xe3\\xec\\x8a\\x1e\\xbey\\xcd\\xc5\\xa0\\xe3\\x0e\\xfe\\xad\\xee\\x93x\\x05\\xfe\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07']\n",
      "Bad pipe message: %s [b'E@oP+\\xbd&\\xbf\\xa7\\xdb\\xc8v\\x7fw\\x97\\xb7\\xc6\\x0b\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0']\n",
      "Bad pipe message: %s [b'\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03']\n",
      "Bad pipe message: %s [b\"\\x8d\\xd2s\\xf9g\\x11 \\xa5\\xb8\\xdd\\xe8\\xe8\\x84n\\x07<\\xe3\\xbc\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\"]\n",
      "Bad pipe message: %s [b'\\x04\\x02\\x04', b'\\x01\\x03', b'\\x03', b'\\x02', b'\\x03']\n",
      "Bad pipe message: %s [b'\\x87\\x0c\\x17\\xd5\\xab\\xd6\\xd8\\xdf\\x11i\\xaaE\\xa9m\\xd7}j\\x1f\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00']\n",
      "Bad pipe message: %s [b\"\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\"]\n",
      "Bad pipe message: %s [b'\\x04\\xc0\\x12\\xc0']\n",
      "Bad pipe message: %s [b'\\x16\\x00\\x13\\x00\\x10\\x00\\r']\n"
     ]
    }
   ],
   "source": [
    "# limit results to 1 for readability\n",
    "# set print_info to true to inspect query string\n",
    "\n",
    "r = query_cosmos(m_cosmos, select='*', limit=1, print_info=True)\n",
    "r[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select: individual fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying central: SELECT c.id FROM c OFFSET 0 LIMIT 1\n",
      "1 results returned\n",
      "['1503158969224814592']\n",
      "Querying central: SELECT c.id, c.text_replaced_b, c.seed_MP FROM c OFFSET 0 LIMIT 1\n",
      "1 results returned\n",
      "[{'id': '1503158969224814592', 'text_replaced_b': 'A very serious question...  Why are the lives and prospects of the homeless and destitute in Britain of less value to the British Government than the undocumented migrants crossing the English Channel from safe-haven-country France? [MP]. Why? You lot are employed by us!', 'seed_MP': ['@pritipatel']}]\n"
     ]
    }
   ],
   "source": [
    "# We can select only the fields we want to return - eg. just tweet id\n",
    "r = query_cosmos_field(m_cosmos, field='id', limit=1, print_info=True)\n",
    "print(r)\n",
    "\n",
    "# We can also select multiple fields\n",
    "r = query_cosmos(m_cosmos, select='c.id, c.text_replaced_b, c.seed_MP', limit=1, print_info=True)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select: document counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying central: SELECT VALUE COUNT(1) FROM c\n",
      "1 results returned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45886884"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = query_cosmos_count(\n",
    "    m_cosmos, \n",
    "    print_info=True\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query based on datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying central: SELECT VALUE COUNT(1) FROM c WHERE c.datetime>=\"2022-02-01T00:00:00.0000000Z\" AND c.datetime<\"2022-03-01T00:00:00.0000000Z\"\n",
      "1 results returned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10853535"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert datetime object to correct format (DT_COSMOS) for query\n",
    "start = dt_string_conversion('01/02/22', DatetimeFormats.DT_DATE, DatetimeFormats.DT_COSMOS)\n",
    "end = dt_string_conversion('01/03/22', DatetimeFormats.DT_DATE, DatetimeFormats.DT_COSMOS)\n",
    "\n",
    "# in the correct format, we can do comparisons on datetime to gets tweet between certain dates and times\n",
    "r = query_cosmos_count(\n",
    "    m_cosmos, \n",
    "    dt_start=start, \n",
    "    dt_end=end, \n",
    "    print_info=True\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query based on variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2805981\n",
      "43539322\n",
      "Querying central: SELECT VALUE COUNT(1) FROM c WHERE ((c.valid=true AND c.bucket=\"audience_contact\") AND (c.type_str=\"standalone\" OR c.type_str=\"reply\"))\n",
      "1 results returned\n",
      "1695323\n"
     ]
    }
   ],
   "source": [
    "# to query by string values, include escaped quotes in the query\n",
    "r = query_cosmos_count(\n",
    "    m_cosmos, \n",
    "    filter=\"c.bucket=\\\"audience_contact\\\"\"\n",
    ")\n",
    "print(r)\n",
    "\n",
    "# to query by boolean values, use lowercase true/false\n",
    "r = query_cosmos_count(\n",
    "    m_cosmos, \n",
    "    filter=\"c.valid=true\"\n",
    ")\n",
    "print(r)\n",
    "\n",
    "# combine multiple filters with AND and OR\n",
    "r = query_cosmos_count(\n",
    "    m_cosmos, \n",
    "    filter=\"(c.valid=true AND c.bucket=\\\"audience_contact\\\") AND (c.type_str=\\\"standalone\\\" OR c.type_str=\\\"reply\\\")\",\n",
    "    print_info=True\n",
    ")\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by tweet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying central: SELECT c.id FROM c OFFSET 0 LIMIT 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batching IDs: 100%|██████████| 999/999 [00:00<00:00, 421879.75it/s]\n",
      "Querying batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 results returned\n",
      "[1000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying batches: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 docs retrieved in 0:00:02.331617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '1503158969224814592',\n",
       " 'text': 'A very serious question...\\n\\nWhy are the lives and prospects of the homeless and destitute in Britain of less value to the British Government than the undocumented migrants crossing the English Channel from safe-haven-country France? @pritipatel. Why? You lot are employed by us!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve documents given a list of tweet IDs\n",
    "\n",
    "tweet_ids = query_cosmos_field(m_cosmos, field='id', limit=1000, print_info=True)\n",
    "\n",
    "r = query_cosmos_by_ids(m_cosmos, ids=tweet_ids, select='c.id, c.text')\n",
    "r[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tweet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503158969224814592</td>\n",
       "      <td>A very serious question...\\n\\nWhy are the live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1503158970059534341</td>\n",
       "      <td>The catastrophic humanitarian crisis in #Tigra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1503158970034311172</td>\n",
       "      <td>The UAE, China, Turkey and Iran continues to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1503158972215443463</td>\n",
       "      <td>For over 16 month 'the Ethiopian government ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1503158975243915271</td>\n",
       "      <td>So @BorisJohnson has ditched the Animals Abroa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1503161097125347333</td>\n",
       "      <td>The Int community has displayed their condemna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1503161098886950920</td>\n",
       "      <td>Tigray Health Bureau's findings confirm 120,00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1503161099327197185</td>\n",
       "      <td>@ai_clayton @AnnDuffieldnews @thecoastguy @All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1503161100489138183</td>\n",
       "      <td>@sajidjavid Profit must be in there as well, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1503161100715675655</td>\n",
       "      <td>@sajidjavid I knew the word CARE would be miss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text\n",
       "0    1503158969224814592  A very serious question...\\n\\nWhy are the live...\n",
       "1    1503158970059534341  The catastrophic humanitarian crisis in #Tigra...\n",
       "2    1503158970034311172  The UAE, China, Turkey and Iran continues to s...\n",
       "3    1503158972215443463  For over 16 month 'the Ethiopian government ha...\n",
       "4    1503158975243915271  So @BorisJohnson has ditched the Animals Abroa...\n",
       "..                   ...                                                ...\n",
       "995  1503161097125347333  The Int community has displayed their condemna...\n",
       "996  1503161098886950920  Tigray Health Bureau's findings confirm 120,00...\n",
       "997  1503161099327197185  @ai_clayton @AnnDuffieldnews @thecoastguy @All...\n",
       "998  1503161100489138183  @sajidjavid Profit must be in there as well, t...\n",
       "999  1503161100715675655  @sajidjavid I knew the word CARE would be miss...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_tweet_df(r, cols=['id','text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample tweets from Cosmos DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total Pool Size  : 20425\n",
      "- Excluded IDs     : N/A\n",
      "- Valid Pool Size  : 20425\n",
      "- Sample size      : 100\n",
      "Retrieved 100 samples from 20425 ids\n"
     ]
    }
   ],
   "source": [
    "# get a random sample of tweet IDs\n",
    "all_ids, valid_ids, sample_ids = get_random_cosmos_sample_ids(\n",
    "    m_cosmos,\n",
    "    n=100,\n",
    "    dt_start=dt_string_conversion('01/02/22', DatetimeFormats.DT_DATE, DatetimeFormats.DT_COSMOS),\n",
    "    dt_end=dt_string_conversion('02/02/22', DatetimeFormats.DT_DATE, DatetimeFormats.DT_COSMOS),\n",
    "    filter=\"c.valid=true AND c.bucket=\\\"audience_contact\\\" AND c.type_str=\\\"standalone\\\"\",\n",
    "    # exclude_ids = [list of ids to exclude, eg. from previous sample]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Getting ids:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batching IDs: 100%|██████████| 9/9 [00:00<00:00, 30198.99it/s]\n",
      "Querying batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total Pool Size  : 1869\n",
      "- Excluded IDs     : N/A\n",
      "- Valid Pool Size  : 1869\n",
      "- Sample size      : 10\n",
      "Retrieved 10 samples from 1869 ids\n",
      "### Saving ids locally to '' (local)\n",
      "### Saving ids to test:\n",
      "### Getting sample docs:\n",
      "[10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying batches: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "Blob Upload: 100%|██████████| 10/10 [00:00<00:00, 53.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 docs retrieved in 0:00:00.393356\n",
      "### Uploading sample docs to blob container test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cs_blob = get_blob_client(CounterSpeechBlobStorage.connect_str, 'test')\n",
    "\n",
    "# get a random sample of documents, uploaded to blob storage, with custom processing step\n",
    "sample_docs = create_random_cosmos_sample(\n",
    "    m_cosmos,\n",
    "    cs_blob,\n",
    "    n=10,\n",
    "    dt_start=dt.datetime.strftime(dt.datetime(2022,2,1,0), DatetimeFormats.DT_COSMOS),\n",
    "    dt_end=dt.datetime.strftime(dt.datetime(2022,2,1,6), DatetimeFormats.DT_COSMOS),\n",
    "    # processing = *function to apply to all docs in sample before upload*\n",
    "    filter=\"c.valid=true AND c.bucket=\\\"audience_contact\\\" AND c.type_str=\\\"standalone\\\"\",\n",
    "    # blob_prefix = *prefix to add to blob name, ie. folder, eg. 'sample1/'*\n",
    "    # save_prefix = *local path to folder, eg. 'sample1/'*\n",
    "    # exclude_ids = [list of ids to exclude, eg. from previous sample]\n",
    "    return_ids=False,\n",
    "    return_docs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create df from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_replaced_b</th>\n",
       "      <th>datetime</th>\n",
       "      <th>seed_MP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488301096439328773</td>\n",
       "      <td>Day 13 It's now just 58 days until the energy ...</td>\n",
       "      <td>2022-02-01T00:00:07.0000000Z</td>\n",
       "      <td>[@BorisJohnson, @KwasiKwarteng]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488303047491334149</td>\n",
       "      <td>Ayder Hospital in Mekelle, the largest hospita...</td>\n",
       "      <td>2022-02-01T00:07:52.0000000Z</td>\n",
       "      <td>[@vickyford]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1488305281830469632</td>\n",
       "      <td>Kudos to those who delivered some home truths ...</td>\n",
       "      <td>2022-02-01T00:16:45.0000000Z</td>\n",
       "      <td>[@DawnButlerBrent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1488331550613819392</td>\n",
       "      <td>Medics from Ayder hospital in Mekelle said mor...</td>\n",
       "      <td>2022-02-01T02:01:08.0000000Z</td>\n",
       "      <td>[@DavidLammy, @lynbrownmp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1488341347392270337</td>\n",
       "      <td>[MP] BULLY!</td>\n",
       "      <td>2022-02-01T02:40:03.0000000Z</td>\n",
       "      <td>[@Ianblackford_MP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1488349589178662912</td>\n",
       "      <td>[MP] please could you explain why there is a n...</td>\n",
       "      <td>2022-02-01T03:12:48.0000000Z</td>\n",
       "      <td>[@BorisJohnson]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1488363404926586882</td>\n",
       "      <td>Thousands of deaths in #Tigray \"overwhelmingly...</td>\n",
       "      <td>2022-02-01T04:07:42.0000000Z</td>\n",
       "      <td>[@SarahChampionMP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1488367634123038723</td>\n",
       "      <td>In #Tigray, half of all pregnant &amp; breastfeedi...</td>\n",
       "      <td>2022-02-01T04:24:31.0000000Z</td>\n",
       "      <td>[@jeremycorbyn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1488377834569621506</td>\n",
       "      <td>The entire population of Tigray is starving. ‘...</td>\n",
       "      <td>2022-02-01T05:05:03.0000000Z</td>\n",
       "      <td>[@vickyford]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1488391444515725313</td>\n",
       "      <td>Good Moaning [MP]   I have come across a book ...</td>\n",
       "      <td>2022-02-01T05:59:08.0000000Z</td>\n",
       "      <td>[@Keir_Starmer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                    text_replaced_b  \\\n",
       "0  1488301096439328773  Day 13 It's now just 58 days until the energy ...   \n",
       "1  1488303047491334149  Ayder Hospital in Mekelle, the largest hospita...   \n",
       "2  1488305281830469632  Kudos to those who delivered some home truths ...   \n",
       "3  1488331550613819392  Medics from Ayder hospital in Mekelle said mor...   \n",
       "4  1488341347392270337                                        [MP] BULLY!   \n",
       "5  1488349589178662912  [MP] please could you explain why there is a n...   \n",
       "6  1488363404926586882  Thousands of deaths in #Tigray \"overwhelmingly...   \n",
       "7  1488367634123038723  In #Tigray, half of all pregnant & breastfeedi...   \n",
       "8  1488377834569621506  The entire population of Tigray is starving. ‘...   \n",
       "9  1488391444515725313  Good Moaning [MP]   I have come across a book ...   \n",
       "\n",
       "                       datetime                          seed_MP  \n",
       "0  2022-02-01T00:00:07.0000000Z  [@BorisJohnson, @KwasiKwarteng]  \n",
       "1  2022-02-01T00:07:52.0000000Z                     [@vickyford]  \n",
       "2  2022-02-01T00:16:45.0000000Z               [@DawnButlerBrent]  \n",
       "3  2022-02-01T02:01:08.0000000Z       [@DavidLammy, @lynbrownmp]  \n",
       "4  2022-02-01T02:40:03.0000000Z               [@Ianblackford_MP]  \n",
       "5  2022-02-01T03:12:48.0000000Z                  [@BorisJohnson]  \n",
       "6  2022-02-01T04:07:42.0000000Z               [@SarahChampionMP]  \n",
       "7  2022-02-01T04:24:31.0000000Z                  [@jeremycorbyn]  \n",
       "8  2022-02-01T05:05:03.0000000Z                     [@vickyford]  \n",
       "9  2022-02-01T05:59:08.0000000Z                  [@Keir_Starmer]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_tweet_df(sample_docs, cols=['id','text_replaced_b','datetime','seed_MP'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blob Storage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_blob = get_blob_client(CounterSpeechBlobStorage.connect_str, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  4\n",
       "1  2  5\n",
       "2  3  6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data={'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "upload_df_to_blob_as_csv(cs_blob, 'testdf', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download csv to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b\n",
       "0  1  4\n",
       "1  2  5\n",
       "2  3  6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = download_csv_from_blob_to_df(cs_blob, 'testdf.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load huggingface models for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Footballer Abuse Model\n",
    "\n",
    "Local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file footballer_abuse_model/tokenizer.json. We won't load it.\n",
      "loading file footballer_abuse_model/spm.model\n",
      "loading file None\n",
      "loading file footballer_abuse_model/added_tokens.json\n",
      "loading file footballer_abuse_model/special_tokens_map.json\n",
      "loading file footballer_abuse_model/tokenizer_config.json\n",
      "Adding [MASK] to the vocabulary\n",
      "Adding [USER] to the vocabulary\n",
      "Adding [PLAYER] to the vocabulary\n",
      "Adding [BODY] to the vocabulary\n",
      "Adding [CLUB] to the vocabulary\n",
      "Adding [URL] to the vocabulary\n",
      "/anaconda/envs/counterspeech/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "loading configuration file footballer_abuse_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"footballer_abuse_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128006\n",
      "}\n",
      "\n",
      "loading weights file footballer_abuse_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at footballer_abuse_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>probs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate you</td>\n",
       "      <td>0.992004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love you</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[MP]  your a schmuck. Imagine if it was your w...</td>\n",
       "      <td>0.961913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     probs  labels\n",
       "0                                         I hate you  0.992004       1\n",
       "1                                         I love you  0.001655       0\n",
       "2  [MP]  your a schmuck. Imagine if it was your w...  0.961913       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HuggingfaceInferenceModel('footballer_abuse_model/', 'temp/', 16)\n",
    "df = model(['I hate you', 'I love you', '[MP]  your a schmuck. Imagine if it was your wife that passed'], return_df=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatemoji\n",
    "\n",
    "Huggingface hosted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/config.json from cache at /home/onlinesafety/.cache/huggingface/transformers/a0c8d234e4a92f0d24045042af6129ea92d0fd9505db052a14b68fda7e420495.7904fe6ee2bb189dc549bfe42f870c902aa3d5f49b3a81862227be11f8f17adb\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"HannahRoseKirk/Hatemoji\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/vocab.json from cache at /home/onlinesafety/.cache/huggingface/transformers/43fad62ef3c18ab40cabb122134fbc380cc2e6713364bad7200ab26cbb63069f.7ea8227b0bb9d081329cc20824d74af3f1dcc30cfc4c83f1d6b85d1807cf5953\n",
      "loading file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/merges.txt from cache at /home/onlinesafety/.cache/huggingface/transformers/1673dc8efb42d18c909d806c9b0054d7a6e0f24975d0fe383084202d662f35a7.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/tokenizer.json from cache at /home/onlinesafety/.cache/huggingface/transformers/850e3990ed95619a7a300f8826aac44d27cd94931d2fe5b5d41a5a57c486bd35.9cf66bb4a2fced3abc9eee05b91f3b2de517a896ce6ed3857f715a58453efcf3\n",
      "loading file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/special_tokens_map.json from cache at /home/onlinesafety/.cache/huggingface/transformers/94214e770272b6478c096f2efb6115b282468e8334f1d8063c505cc38f34bb18.8775b0b36c5f216ff7141ca01c145da1366c7b354621dbe2241b6278d603ee0e\n",
      "loading file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/tokenizer_config.json from cache at /home/onlinesafety/.cache/huggingface/transformers/2eb107e998fd088c7c0236d2387cfa1bb2dc4d6301c13dbe31bd3047d0521dcd.0260de022e4f443d358806dba202446ebb79d18ca7a9ecd2e4700f953b3bf521\n",
      "loading configuration file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/config.json from cache at /home/onlinesafety/.cache/huggingface/transformers/a0c8d234e4a92f0d24045042af6129ea92d0fd9505db052a14b68fda7e420495.7904fe6ee2bb189dc549bfe42f870c902aa3d5f49b3a81862227be11f8f17adb\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"HannahRoseKirk/Hatemoji\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/config.json from cache at /home/onlinesafety/.cache/huggingface/transformers/a0c8d234e4a92f0d24045042af6129ea92d0fd9505db052a14b68fda7e420495.7904fe6ee2bb189dc549bfe42f870c902aa3d5f49b3a81862227be11f8f17adb\n",
      "Model config DebertaConfig {\n",
      "  \"_name_or_path\": \"HannahRoseKirk/Hatemoji\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"c2p\",\n",
      "    \"p2c\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"relative_attention\": true,\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/HannahRoseKirk/Hatemoji/resolve/main/pytorch_model.bin from cache at /home/onlinesafety/.cache/huggingface/transformers/b9671675a895913aecb4bcae25679fb673089bf89ec042abb0535025ab968356.1f6a7b27c0f0a9c1bbc755430ff1e523394261eb203e264c715be788fe355273\n",
      "All model checkpoint weights were used when initializing DebertaForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaForSequenceClassification were initialized from the model checkpoint at HannahRoseKirk/Hatemoji.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>probs</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I hate you</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love you</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[MP]  your a schmuck. Imagine if it was your w...</td>\n",
       "      <td>0.841205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     probs  labels\n",
       "0                                         I hate you  0.000040       0\n",
       "1                                         I love you  0.000038       0\n",
       "2  [MP]  your a schmuck. Imagine if it was your w...  0.841205       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HuggingfaceInferenceModel('HannahRoseKirk/Hatemoji', 'temp/', 16)\n",
    "df = model(['I hate you', 'I love you', '[MP]  your a schmuck. Imagine if it was your wife that passed'], return_df=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfab6340c2e6527cde9f13c21389f22664c035af36a415c4c273e7b5750974e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('counterspeech')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
