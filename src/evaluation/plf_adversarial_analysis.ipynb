{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic analysis of authentic and adversarial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_plf = pd.read_csv(\"../../data/authentic_data/counter_abuse_plf_annotated.csv\")\n",
    "df_adv = pd.read_csv(\"../../data/adversarial_data/responses_annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plf['counter_speech_processed'] = df_plf['counter_speech'].map(lambda x: x.replace(\"[USER]\", \"\").replace(\"[PLAYER]\", \"\").replace(\"[CLUB]\", \"\").replace(\"[URL]\", \"\").strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "multiclass_classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "\n",
    "def count_tokens(text):\n",
    "    doc = nlp(text)\n",
    "    return len(doc)\n",
    "\n",
    "def most_common(lst):\n",
    "    data = Counter(lst)\n",
    "    if len(data) > 0:\n",
    "        if len(data) > 1:\n",
    "            if data.most_common(1)[0][1] == data.most_common()[1][1]:\n",
    "                return [data.most_common(1)[0][0], data.most_common()[1][0]]\n",
    "        return data.most_common(1)[0][0]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def get_ne(text):\n",
    "    doc = nlp(text)\n",
    "    ne_list = []\n",
    "    for ent in doc.ents:\n",
    "        ne_list.append(ent.label_)\n",
    "    return most_common(ne_list)\n",
    "    \n",
    "def count_pronoun(text):\n",
    "    doc = nlp(text)\n",
    "    cnt = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PROPN':\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def count_negation(text):\n",
    "    doc = nlp(text)\n",
    "    cnt = 0\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'neg':\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def sentiment_analysis(text):\n",
    "    return sentiment_pipeline([text])[0]['label']\n",
    "\n",
    "def multiclass_sentiment_analysis(text):\n",
    "    model_outputs = multiclass_classifier([text])\n",
    "    return model_outputs[0][0]['label']\n",
    "\n",
    "\n",
    "def process_ne(ne):\n",
    "    if type(ne) == str:\n",
    "        if len(ne) > 0:\n",
    "            return ne\n",
    "        return \"no entity\"\n",
    "    else:\n",
    "        return \"most common entity > 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv['count_tokens'] = df_adv.apply(lambda x: count_tokens(x['context']), axis = 1)\n",
    "df_adv['get_ne'] = df_adv.apply(lambda x: get_ne(x['context']), axis = 1)\n",
    "df_adv['count_pronoun'] = df_adv.apply(lambda x: count_pronoun(x['context']), axis = 1)\n",
    "df_adv['count_negation'] = df_adv.apply(lambda x: count_negation(x['context']), axis = 1)\n",
    "df_adv['sentiment_analysis'] = df_adv.apply(lambda x: sentiment_analysis(x['context']), axis = 1)\n",
    "df_adv['multiclass_sentiment_analysis'] = df_adv.apply(lambda x: multiclass_sentiment_analysis(x['context']), axis = 1)\n",
    "\n",
    "df_plf['count_tokens'] = df_plf.apply(lambda x: count_tokens(x['counter_speech_processed']), axis = 1)\n",
    "df_plf['get_ne'] = df_plf.apply(lambda x: get_ne(x['counter_speech_processed']), axis = 1)\n",
    "df_plf['count_pronoun'] = df_plf.apply(lambda x: count_pronoun(x['counter_speech_processed']), axis = 1)\n",
    "df_plf['count_negation'] = df_plf.apply(lambda x: count_negation(x['counter_speech_processed']), axis = 1)\n",
    "df_plf['sentiment_analysis'] = df_plf.apply(lambda x: sentiment_analysis(x['counter_speech_processed']), axis = 1)\n",
    "df_plf['multiclass_sentiment_analysis'] = df_plf.apply(lambda x: multiclass_sentiment_analysis(x['counter_speech_processed']), axis = 1)\n",
    "\n",
    "df_plf['get_ne_most'] = df_plf.apply(lambda x: process_ne(x['get_ne']), axis = 1)\n",
    "df_adv['get_ne_most'] = df_adv.apply(lambda x: process_ne(x['get_ne']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv.to_csv(\"../../data/adversarial_data/responses_annotated_linguistic_analysis.csv\")\n",
    "df_plf.to_csv(\"../../data/authentic_data/counter_abuse_plf_annotated_linguistic_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = pd.read_csv(\"../../data/adversarial_data/responses_annotated_linguistic_analysis.csv\")\n",
    "df_plf = pd.read_csv(\"../../data/authentic_data/counter_abuse_plf_annotated_linguistic_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plf_agree = df_plf[df_plf['label'] == 'agrees_with_the_post']\n",
    "df_plf_disagree = df_plf[df_plf['label'] == 'disagrees_with_the_post']\n",
    "df_plf_other = df_plf[df_plf['label'] == 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1173, 2124, 159, 3456)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_plf_agree), len(df_plf_disagree), len(df_plf_other), 1173+2124+159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1911.000000\n",
      "mean       19.576138\n",
      "std         7.604513\n",
      "min         1.000000\n",
      "25%        14.000000\n",
      "50%        20.000000\n",
      "75%        27.000000\n",
      "max        42.000000\n",
      "Name: count_tokens, dtype: float64\n",
      "count    3456.000000\n",
      "mean       14.612847\n",
      "std        13.149986\n",
      "min         1.000000\n",
      "25%         6.000000\n",
      "50%        10.000000\n",
      "75%        19.000000\n",
      "max        87.000000\n",
      "Name: count_tokens, dtype: float64\n",
      "count    1173.000000\n",
      "mean       13.640239\n",
      "std        12.199080\n",
      "min         1.000000\n",
      "25%         5.000000\n",
      "50%        10.000000\n",
      "75%        18.000000\n",
      "max        63.000000\n",
      "Name: count_tokens, dtype: float64\n",
      "count    2124.000000\n",
      "mean       15.627119\n",
      "std        13.634981\n",
      "min         1.000000\n",
      "25%         7.000000\n",
      "50%        11.000000\n",
      "75%        20.000000\n",
      "max        87.000000\n",
      "Name: count_tokens, dtype: float64\n",
      "count    159.000000\n",
      "mean       8.238994\n",
      "std       10.845555\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        5.000000\n",
      "75%        8.000000\n",
      "max       57.000000\n",
      "Name: count_tokens, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_adv['count_tokens'].describe())\n",
    "print(df_plf['count_tokens'].describe())\n",
    "print(df_plf_agree['count_tokens'].describe())\n",
    "print(df_plf_disagree['count_tokens'].describe())\n",
    "print(df_plf_other['count_tokens'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_ne_most\n",
      "CARDINAL                  0.010466\n",
      "DATE                      0.010989\n",
      "EVENT                     0.000523\n",
      "GPE                       0.060701\n",
      "LANGUAGE                  0.013605\n",
      "LOC                       0.008896\n",
      "NORP                      0.217164\n",
      "ORDINAL                   0.009419\n",
      "ORG                       0.004710\n",
      "PERCENT                   0.000523\n",
      "PERSON                    0.007326\n",
      "QUANTITY                  0.000523\n",
      "TIME                      0.001570\n",
      "WORK_OF_ART               0.001047\n",
      "most common entity > 1    0.051282\n",
      "no entity                 0.601256\n",
      "Name: proportion, dtype: float64\n",
      "get_ne_most\n",
      "CARDINAL                  0.039062\n",
      "DATE                      0.026910\n",
      "EVENT                     0.000579\n",
      "FAC                       0.002025\n",
      "GPE                       0.028935\n",
      "LANGUAGE                  0.001736\n",
      "LOC                       0.002315\n",
      "MONEY                     0.002315\n",
      "NORP                      0.010417\n",
      "ORDINAL                   0.006366\n",
      "ORG                       0.055556\n",
      "PERCENT                   0.001447\n",
      "PERSON                    0.103877\n",
      "PRODUCT                   0.006366\n",
      "QUANTITY                  0.001447\n",
      "TIME                      0.006076\n",
      "WORK_OF_ART               0.002604\n",
      "most common entity > 1    0.078125\n",
      "no entity                 0.623843\n",
      "Name: proportion, dtype: float64\n",
      "------------------\n",
      "get_ne_most\n",
      "CARDINAL                  0.028133\n",
      "DATE                      0.028986\n",
      "EVENT                     0.000853\n",
      "FAC                       0.001705\n",
      "GPE                       0.021313\n",
      "LANGUAGE                  0.000853\n",
      "LOC                       0.001705\n",
      "MONEY                     0.000853\n",
      "NORP                      0.006820\n",
      "ORDINAL                   0.004263\n",
      "ORG                       0.049446\n",
      "PERCENT                   0.003410\n",
      "PERSON                    0.099744\n",
      "PRODUCT                   0.006820\n",
      "QUANTITY                  0.000853\n",
      "TIME                      0.005115\n",
      "WORK_OF_ART               0.002558\n",
      "most common entity > 1    0.074169\n",
      "no entity                 0.662404\n",
      "Name: proportion, dtype: float64\n",
      "get_ne_most\n",
      "CARDINAL                  0.044727\n",
      "DATE                      0.026836\n",
      "EVENT                     0.000471\n",
      "FAC                       0.002354\n",
      "GPE                       0.033898\n",
      "LANGUAGE                  0.002354\n",
      "LOC                       0.002825\n",
      "MONEY                     0.003296\n",
      "NORP                      0.012712\n",
      "ORDINAL                   0.008004\n",
      "ORG                       0.061205\n",
      "PERCENT                   0.000471\n",
      "PERSON                    0.104049\n",
      "PRODUCT                   0.006591\n",
      "QUANTITY                  0.001883\n",
      "TIME                      0.007062\n",
      "WORK_OF_ART               0.002825\n",
      "most common entity > 1    0.080508\n",
      "no entity                 0.597928\n",
      "Name: proportion, dtype: float64\n",
      "get_ne_most\n",
      "CARDINAL                  0.044025\n",
      "DATE                      0.012579\n",
      "GPE                       0.018868\n",
      "NORP                      0.006289\n",
      "ORG                       0.025157\n",
      "PERSON                    0.132075\n",
      "most common entity > 1    0.075472\n",
      "no entity                 0.685535\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_adv['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print('------------------')\n",
    "print(df_plf_agree['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_disagree['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_other['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_pronoun\n",
      "0     0.732077\n",
      "1     0.162219\n",
      "2     0.076400\n",
      "3     0.019362\n",
      "4     0.005233\n",
      "5     0.002093\n",
      "6     0.001570\n",
      "7     0.000523\n",
      "11    0.000523\n",
      "Name: proportion, dtype: float64\n",
      "count_pronoun\n",
      "0     0.579572\n",
      "1     0.216725\n",
      "2     0.106481\n",
      "3     0.048032\n",
      "4     0.021123\n",
      "5     0.012153\n",
      "6     0.006366\n",
      "7     0.001736\n",
      "8     0.001447\n",
      "9     0.001447\n",
      "10    0.000579\n",
      "11    0.002025\n",
      "12    0.000289\n",
      "13    0.000289\n",
      "15    0.000289\n",
      "16    0.000289\n",
      "17    0.000289\n",
      "19    0.000289\n",
      "21    0.000289\n",
      "23    0.000289\n",
      "Name: proportion, dtype: float64\n",
      "------------------\n",
      "count_pronoun\n",
      "0     0.620631\n",
      "1     0.190963\n",
      "2     0.102302\n",
      "3     0.043478\n",
      "4     0.021313\n",
      "5     0.008525\n",
      "6     0.004263\n",
      "7     0.001705\n",
      "8     0.000853\n",
      "9     0.001705\n",
      "10    0.000853\n",
      "11    0.000853\n",
      "12    0.000853\n",
      "16    0.000853\n",
      "21    0.000853\n",
      "Name: proportion, dtype: float64\n",
      "count_pronoun\n",
      "0     0.556968\n",
      "1     0.229755\n",
      "2     0.109228\n",
      "3     0.052260\n",
      "4     0.021657\n",
      "5     0.014124\n",
      "6     0.007533\n",
      "7     0.001412\n",
      "8     0.001412\n",
      "9     0.000942\n",
      "10    0.000471\n",
      "11    0.002825\n",
      "13    0.000471\n",
      "15    0.000471\n",
      "19    0.000471\n",
      "Name: proportion, dtype: float64\n",
      "count_pronoun\n",
      "0     0.578616\n",
      "1     0.232704\n",
      "2     0.100629\n",
      "3     0.025157\n",
      "4     0.012579\n",
      "5     0.012579\n",
      "6     0.006289\n",
      "7     0.006289\n",
      "8     0.006289\n",
      "9     0.006289\n",
      "17    0.006289\n",
      "23    0.006289\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_adv['count_pronoun'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf['count_pronoun'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print('------------------')\n",
    "print(df_plf_agree['count_pronoun'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_disagree['count_pronoun'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_other['count_pronoun'].value_counts(normalize=True).sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_negation\n",
      "0    0.652538\n",
      "1    0.264783\n",
      "2    0.068550\n",
      "3    0.010989\n",
      "4    0.002616\n",
      "5    0.000523\n",
      "Name: proportion, dtype: float64\n",
      "count_negation\n",
      "0    0.774016\n",
      "1    0.190972\n",
      "2    0.028935\n",
      "3    0.004340\n",
      "4    0.001157\n",
      "5    0.000579\n",
      "Name: proportion, dtype: float64\n",
      "------------------\n",
      "count_negation\n",
      "0    0.796249\n",
      "1    0.177323\n",
      "2    0.023018\n",
      "3    0.002558\n",
      "4    0.000853\n",
      "Name: proportion, dtype: float64\n",
      "count_negation\n",
      "0    0.748588\n",
      "1    0.209981\n",
      "2    0.033427\n",
      "3    0.005650\n",
      "4    0.001412\n",
      "5    0.000942\n",
      "Name: proportion, dtype: float64\n",
      "count_negation\n",
      "0    0.949686\n",
      "1    0.037736\n",
      "2    0.012579\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_adv['count_negation'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf['count_negation'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print('------------------')\n",
    "print(df_plf_agree['count_negation'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_disagree['count_negation'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_other['count_negation'].value_counts(normalize=True).sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_analysis\n",
      "NEGATIVE    0.77551\n",
      "POSITIVE    0.22449\n",
      "Name: proportion, dtype: float64\n",
      "sentiment_analysis\n",
      "NEGATIVE    0.697338\n",
      "POSITIVE    0.302662\n",
      "Name: proportion, dtype: float64\n",
      "------------------\n",
      "sentiment_analysis\n",
      "NEGATIVE    0.707587\n",
      "POSITIVE    0.292413\n",
      "Name: proportion, dtype: float64\n",
      "sentiment_analysis\n",
      "NEGATIVE    0.698211\n",
      "POSITIVE    0.301789\n",
      "Name: proportion, dtype: float64\n",
      "sentiment_analysis\n",
      "NEGATIVE    0.610063\n",
      "POSITIVE    0.389937\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_adv['sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf['sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print('------------------')\n",
    "print(df_plf_agree['sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_disagree['sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_other['sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass_sentiment_analysis\n",
      "admiration        0.037677\n",
      "amusement         0.007849\n",
      "anger             0.025118\n",
      "annoyance         0.045003\n",
      "approval          0.050759\n",
      "caring            0.016745\n",
      "confusion         0.009419\n",
      "curiosity         0.022501\n",
      "desire            0.015699\n",
      "disappointment    0.024071\n",
      "disapproval       0.085819\n",
      "disgust           0.013605\n",
      "embarrassment     0.001047\n",
      "excitement        0.001570\n",
      "fear              0.009419\n",
      "gratitude         0.004186\n",
      "joy               0.005756\n",
      "love              0.002616\n",
      "nervousness       0.001570\n",
      "neutral           0.593407\n",
      "optimism          0.004710\n",
      "pride             0.001570\n",
      "realization       0.007326\n",
      "remorse           0.001570\n",
      "sadness           0.009419\n",
      "surprise          0.001570\n",
      "Name: proportion, dtype: float64\n",
      "multiclass_sentiment_analysis\n",
      "admiration        0.042245\n",
      "amusement         0.040509\n",
      "anger             0.075231\n",
      "annoyance         0.066262\n",
      "approval          0.035880\n",
      "caring            0.015914\n",
      "confusion         0.010417\n",
      "curiosity         0.061921\n",
      "desire            0.006366\n",
      "disappointment    0.012442\n",
      "disapproval       0.029514\n",
      "disgust           0.028356\n",
      "embarrassment     0.008391\n",
      "excitement        0.003762\n",
      "fear              0.006366\n",
      "gratitude         0.006655\n",
      "joy               0.010417\n",
      "love              0.015625\n",
      "nervousness       0.000289\n",
      "neutral           0.453704\n",
      "optimism          0.026331\n",
      "realization       0.002315\n",
      "remorse           0.005787\n",
      "sadness           0.026910\n",
      "surprise          0.008391\n",
      "Name: proportion, dtype: float64\n",
      "------------------\n",
      "multiclass_sentiment_analysis\n",
      "admiration        0.034101\n",
      "amusement         0.036658\n",
      "anger             0.086104\n",
      "annoyance         0.069054\n",
      "approval          0.051151\n",
      "caring            0.011935\n",
      "confusion         0.011083\n",
      "curiosity         0.038363\n",
      "desire            0.006820\n",
      "disappointment    0.017050\n",
      "disapproval       0.023018\n",
      "disgust           0.040068\n",
      "embarrassment     0.009378\n",
      "excitement        0.004263\n",
      "fear              0.010230\n",
      "gratitude         0.008525\n",
      "joy               0.008525\n",
      "love              0.015345\n",
      "neutral           0.439045\n",
      "optimism          0.029838\n",
      "realization       0.000853\n",
      "remorse           0.008525\n",
      "sadness           0.030691\n",
      "surprise          0.009378\n",
      "Name: proportion, dtype: float64\n",
      "multiclass_sentiment_analysis\n",
      "admiration        0.048964\n",
      "amusement         0.040960\n",
      "anger             0.073917\n",
      "annoyance         0.068738\n",
      "approval          0.028249\n",
      "caring            0.018832\n",
      "confusion         0.010358\n",
      "curiosity         0.076742\n",
      "desire            0.006591\n",
      "disappointment    0.010829\n",
      "disapproval       0.035311\n",
      "disgust           0.024011\n",
      "embarrassment     0.008004\n",
      "excitement        0.003766\n",
      "fear              0.004708\n",
      "gratitude         0.005179\n",
      "joy               0.010358\n",
      "love              0.016949\n",
      "nervousness       0.000471\n",
      "neutral           0.441620\n",
      "optimism          0.024482\n",
      "realization       0.003296\n",
      "remorse           0.004708\n",
      "sadness           0.025424\n",
      "surprise          0.007533\n",
      "Name: proportion, dtype: float64\n",
      "multiclass_sentiment_analysis\n",
      "admiration       0.012579\n",
      "amusement        0.062893\n",
      "anger            0.012579\n",
      "annoyance        0.012579\n",
      "approval         0.025157\n",
      "caring           0.006289\n",
      "confusion        0.006289\n",
      "curiosity        0.037736\n",
      "embarrassment    0.006289\n",
      "gratitude        0.012579\n",
      "joy              0.025157\n",
      "neutral          0.723270\n",
      "optimism         0.025157\n",
      "sadness          0.018868\n",
      "surprise         0.012579\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_adv['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print('------------------')\n",
    "print(df_plf_agree['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_disagree['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))\n",
    "print(df_plf_other['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plf_disagree['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True).to_csv(\"plf_named_entity_most_disagree.csv\")\n",
    "df_plf_agree['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True).to_csv(\"plf_named_entity_most_agree.csv\")\n",
    "df_plf_other['get_ne_most'].value_counts(normalize=True).sort_index(ascending=True).to_csv(\"plf_named_entity_most_other.csv\")\n",
    "df_plf_disagree['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True).to_csv(\"plf_multiclass_sentiment_analysis_disagree.csv\")\n",
    "df_plf_agree['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True).to_csv(\"plf_multiclass_sentiment_analysis_agree.csv\")\n",
    "df_plf_other['multiclass_sentiment_analysis'].value_counts(normalize=True).sort_index(ascending=True).to_csv(\"plf_multiclass_sentiment_analysis_other.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plf_disagree['get_ne_most'].value_counts().sort_index(ascending=True).to_csv(\"plf_named_entity_cnt_most_disagree.csv\")\n",
    "df_plf_agree['get_ne_most'].value_counts().sort_index(ascending=True).to_csv(\"plf_named_entity_cnt_most_agree.csv\")\n",
    "df_plf_other['get_ne_most'].value_counts().sort_index(ascending=True).to_csv(\"plf_named_entity_cnt_most_other.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health_misinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
